<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: swift | Hacker and Geeker's Way]]></title>
  <link href="http://zhaozhiming.github.io/tags/swift/atom.xml" rel="self"/>
  <link href="http://zhaozhiming.github.io/"/>
  <updated>2016-05-31T21:00:13+08:00</updated>
  <id>http://zhaozhiming.github.io/</id>
  <author>
    <name><![CDATA[赵芝明]]></name>
    <email><![CDATA[kingzzm1982@sina.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[swift源码详解（三）——proxy/controllers/base.py]]></title>
    <link href="http://zhaozhiming.github.io/blog/2014/05/04/swift-code-explain-3-proxy-controllers-base/"/>
    <updated>2014-05-04T21:36:00+08:00</updated>
    <id>http://zhaozhiming.github.io/blog/2014/05/04/swift-code-explain-3-proxy-controllers-base</id>
    <content type="html"><![CDATA[<h2><a href="http://zhaozhiming.github.io/blog/2014/04/19/swift-code-explain-total/">回swift代码结构目录</a></h2>

<h3>update_headers</h3>

<!--more-->


<p>
{% codeblock lang:python %}
def update_headers(response, headers):</p>

<pre><code>"""
Helper function to update headers in the response.

:param response: swob.Response object
:param headers: dictionary headers
"""
if hasattr(headers, 'items'):
    headers = headers.items()
for name, value in headers:
    if name == 'etag':
        response.headers[name] = value.replace('"', '')
    elif name not in ('date', 'content-length', 'content-type',
                      'connection', 'x-put-timestamp', 'x-delete-after'):
        response.headers[name] = value
</code></pre>

<p>{% endcodeblock %}<br/>
* 更新response的header。
* 查看headers中是否'items'属性，有的话给headers赋值。
* 遍历headers中的每个header,如果是'etag'，则去除值中的双引号，并写到response的header中，如果header不是特殊的header，则写到response的header中。</p>

<h3>source_key</h3>

<p>{% codeblock lang:python %}
def source_key(resp):</p>

<pre><code>"""
Provide the timestamp of the swift http response as a floating
point value.  Used as a sort key.

:param resp: bufferedhttp response object
"""
return float(resp.getheader('x-put-timestamp') or
             resp.getheader('x-timestamp') or 0)
</code></pre>

<p>{% endcodeblock %}<br/>
* 依次获取response中的header'x-put-timestamp'和'x-timestamp'的值，如果有值则返回，没有则返回0。</p>

<h3>delay_denial</h3>

<p>{% codeblock lang:python %}
def delay_denial(func):</p>

<pre><code>"""
Decorator to declare which methods should have any swift.authorize call
delayed. This is so the method can load the Request object up with
additional information that may be needed by the authorization system.

:param func: function for which authorization will be delayed
"""
func.delay_denial = True

@functools.wraps(func)
def wrapped(*a, **kw):
    return func(*a, **kw)
return wrapped
</code></pre>

<p>{% endcodeblock %}<br/>
* 方法标签，标识了该标签的方法表示与swift.authorize有关，会延迟认证。</p>

<h3>get_account_memcache_key</h3>

<p>{% codeblock lang:python %}
def get_account_memcache_key(account):</p>

<pre><code>cache_key, env_key = _get_cache_key(account, None)
return cache_key
</code></pre>

<p>{% endcodeblock %}<br/>
* 获取account的缓存key。</p>

<h3>get_container_memcache_key</h3>

<p>{% codeblock lang:python %}
def get_container_memcache_key(account, container):</p>

<pre><code>if not container:
    raise ValueError("container not provided")
cache_key, env_key = _get_cache_key(account, container)
return cache_key
</code></pre>

<p>{% endcodeblock %}<br/>
* 获取container的缓存key。</p>

<h3>_prep_headers_to_info</h3>

<p>{% codeblock lang:python %}
def _prep_headers_to_info(headers, server_type):</p>

<pre><code>"""
Helper method that iterates once over a dict of headers,
converting all keys to lower case and separating
into subsets containing user metadata, system metadata
and other headers.
"""
meta = {}
sysmeta = {}
other = {}
for key, val in dict(headers).iteritems():
    lkey = key.lower()
    if is_user_meta(server_type, lkey):
        meta[strip_user_meta_prefix(server_type, lkey)] = val
    elif is_sys_meta(server_type, lkey):
        sysmeta[strip_sys_meta_prefix(server_type, lkey)] = val
    else:
        other[lkey] = val
return other, meta, sysmeta
</code></pre>

<p>{% endcodeblock %}<br/>
* 将header根据server_type进行分类，以x-<em>-meta开头的为用户信息类，以x-</em>-sysmeta开头的为系统信息类，其他的为other类。</p>

<h3>headers_to_account_info</h3>

<p>{% codeblock lang:python %}
def headers_to_account_info(headers, status_int=HTTP_OK):</p>

<pre><code>"""
Construct a cacheable dict of account info based on response headers.
"""
headers, meta, sysmeta = _prep_headers_to_info(headers, 'account')
return {
    'status': status_int,
    # 'container_count' anomaly:
    # Previous code sometimes expects an int sometimes a string
    # Current code aligns to str and None, yet translates to int in
    # deprecated functions as needed
    'container_count': headers.get('x-account-container-count'),
    'total_object_count': headers.get('x-account-object-count'),
    'bytes': headers.get('x-account-bytes-used'),
    'meta': meta,
    'sysmeta': sysmeta
}
</code></pre>

<p>{% endcodeblock %}<br/>
* 将account的header进行分类，返回包含account信息的字典。</p>

<h3>headers_to_container_info</h3>

<p>{% codeblock lang:python %}
def headers_to_container_info(headers, status_int=HTTP_OK):</p>

<pre><code>"""
Construct a cacheable dict of container info based on response headers.
"""
headers, meta, sysmeta = _prep_headers_to_info(headers, 'container')
return {
    'status': status_int,
    'read_acl': headers.get('x-container-read'),
    'write_acl': headers.get('x-container-write'),
    'sync_key': headers.get('x-container-sync-key'),
    'object_count': headers.get('x-container-object-count'),
    'bytes': headers.get('x-container-bytes-used'),
    'versions': headers.get('x-versions-location'),
    'cors': {
        'allow_origin': meta.get('access-control-allow-origin'),
        'expose_headers': meta.get('access-control-expose-headers'),
        'max_age': meta.get('access-control-max-age')
    },
    'meta': meta,
    'sysmeta': sysmeta
}
</code></pre>

<p>{% endcodeblock %}<br/>
* 将container的header进行分类，返回包含container信息的字典。</p>

<h3>headers_to_object_info</h3>

<p>{% codeblock lang:python %}
def headers_to_object_info(headers, status_int=HTTP_OK):</p>

<pre><code>"""
Construct a cacheable dict of object info based on response headers.
"""
headers, meta, sysmeta = _prep_headers_to_info(headers, 'object')
info = {'status': status_int,
        'length': headers.get('content-length'),
        'type': headers.get('content-type'),
        'etag': headers.get('etag'),
        'meta': meta
        }
return info
</code></pre>

<p>{% endcodeblock %}<br/>
* 将object的header进行分类，返回包含object信息的字典。</p>

<h3>cors_validation</h3>

<p>{% codeblock lang:python %}
def cors_validation(func):</p>

<pre><code>"""
Decorator to check if the request is a CORS request and if so, if it's
valid.

:param func: function to check
"""
@functools.wraps(func)
def wrapped(*a, **kw):
    controller = a[0]
    req = a[1]

    # The logic here was interpreted from
    #    http://www.w3.org/TR/cors/#resource-requests

    # Is this a CORS request?
    req_origin = req.headers.get('Origin', None)
    if req_origin:
        # Yes, this is a CORS request so test if the origin is allowed
        container_info = \
            controller.container_info(controller.account_name,
                                      controller.container_name, req)
        cors_info = container_info.get('cors', {})

        # Call through to the decorated method
        resp = func(*a, **kw)

        if controller.app.strict_cors_mode and \
                not controller.is_origin_allowed(cors_info, req_origin):
            return resp
</code></pre>

<p>{% endcodeblock %}<br/>
* 方法标签，对CORS请求进行验证。
* 先判断该请求是否是一个跨域资源共享（CORS）请求，是的话先获取container的信息，再根据container信息获取cors信息。
* 如果controller的cors mode存在就判断原请求是否被允许，允许的话返回response。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        # Expose,
        #  - simple response headers,
        #    http://www.w3.org/TR/cors/#simple-response-header
        #  - swift specific: etag, x-timestamp, x-trans-id
        #  - user metadata headers
        #  - headers provided by the user in
        #    x-container-meta-access-control-expose-headers
        if 'Access-Control-Expose-Headers' not in resp.headers:
            expose_headers = [
                'cache-control', 'content-language', 'content-type',
                'expires', 'last-modified', 'pragma', 'etag',
                'x-timestamp', 'x-trans-id']
            for header in resp.headers:
                if header.startswith('X-Container-Meta') or \
                        header.startswith('X-Object-Meta'):
                    expose_headers.append(header.lower())
            if cors_info.get('expose_headers'):
                expose_headers.extend(
                    [header_line.strip()
                     for header_line in
                     cors_info['expose_headers'].split(' ')
                     if header_line.strip()])
            resp.headers['Access-Control-Expose-Headers'] = \
                ', '.join(expose_headers)
</code></pre>

<p>{% endcodeblock %}<br/>
* 方法标签，对CORS请求进行验证。
* 先判断该请求是否是一个跨域资源共享（CORS）请求，是的话先获取container的信息，再根据container信息获取cors信息。
* 根据controller的cors mode判断cors请求是否被允许，是的话返回response。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        # The user agent won't process the response if the Allow-Origin
        # header isn't included
        if 'Access-Control-Allow-Origin' not in resp.headers:
            if cors_info['allow_origin'] and \
                    cors_info['allow_origin'].strip() == '*':
                resp.headers['Access-Control-Allow-Origin'] = '*'
            else:
                resp.headers['Access-Control-Allow-Origin'] = req_origin

        return  resp
    else:
        # Not a CORS request so make the call as normal
        return func(*a, **kw)

return wrapped
</code></pre>

<p>{% endcodeblock %}<br/>
* 如果response里面不包含'Access-Control-Allow-Origin' header，则加上该header。</p>

<h3>get_object_info</h3>

<p>{% codeblock lang:python %}
def get_object_info(env, app, path=None, swift_source=None):</p>

<pre><code>"""
Get the info structure for an object, based on env and app.
This is useful to middlewares.

.. note::

    This call bypasses auth. Success does not imply that the request has
    authorization to the object.
"""
(version, account, container, obj) = \
    split_path(path or env['PATH_INFO'], 4, 4, True)
info = _get_object_info(app, env, account, container, obj,
                        swift_source=swift_source)
if not info:
    info = headers_to_object_info({}, 0)
return info
</code></pre>

<p>{% endcodeblock %}<br/>
* 根据env和app获取object的结构信息。</p>

<h3>get_container_info</h3>

<p>{% codeblock lang:python %}
def get_container_info(env, app, swift_source=None):</p>

<pre><code>"""
Get the info structure for a container, based on env and app.
This is useful to middlewares.

.. note::

    This call bypasses auth. Success does not imply that the request has
    authorization to the container.
"""
(version, account, container, unused) = \
    split_path(env['PATH_INFO'], 3, 4, True)
info = get_info(app, env, account, container, ret_not_found=True,
                swift_source=swift_source)
if not info:
    info = headers_to_container_info({}, 0)
return info
</code></pre>

<p>{% endcodeblock %}<br/>
* 根据env和app获取container的结构信息。</p>

<h3>get_account_info</h3>

<p>{% codeblock lang:python %}
def get_account_info(env, app, swift_source=None):</p>

<pre><code>"""
Get the info structure for an account, based on env and app.
This is useful to middlewares.

.. note::

    This call bypasses auth. Success does not imply that the request has
    authorization to the account.
"""
(version, account, _junk, _junk) = \
    split_path(env['PATH_INFO'], 2, 4, True)
info = get_info(app, env, account, ret_not_found=True,
                swift_source=swift_source)
if not info:
    info = headers_to_account_info({}, 0)
if info.get('container_count') is None:
    info['container_count'] = 0
else:
    info['container_count'] = int(info['container_count'])
return info
</code></pre>

<p>{% endcodeblock %}<br/>
* 根据env和app获取account的结构信息。</p>

<h3>_get_cache_key</h3>

<p>{% codeblock lang:python %}
def _get_cache_key(account, container):</p>

<pre><code>"""
Get the keys for both memcache (cache_key) and env (env_key)
where info about accounts and containers is cached
:param   account: The name of the account
:param container: The name of the container (or None if account)
:returns a tuple of (cache_key, env_key)
"""

if container:
    cache_key = 'container/%s/%s' % (account, container)
else:
    cache_key = 'account/%s' % account
# Use a unique environment cache key per account and one container.
# This allows caching both account and container and ensures that when we
# copy this env to form a new request, it won't accidentally reuse the
# old container or account info
env_key = 'swift.%s' % cache_key
return cache_key, env_key
</code></pre>

<p>{% endcodeblock %}<br/>
* 获取account和container的缓存key，account是'account/account名'，container是'container/account名/container名'，还有env_key，值为'swift.缓存key'。</p>

<h3>get_object_env_key</h3>

<p>{% codeblock lang:python %}
def get_object_env_key(account, container, obj):</p>

<pre><code>"""
Get the keys for env (env_key) where info about object is cached
:param   account: The name of the account
:param container: The name of the container
:param obj: The name of the object
:returns a string env_key
"""
env_key = 'swift.object/%s/%s/%s' % (account,
                                     container, obj)
return env_key
</code></pre>

<p>{% endcodeblock %}<br/>
* 得到object的env_key，值为'swift.object/account名/container名/object名。</p>

<h3>set_info_cache</h3>

<p>{% codeblock lang:python %}
def _set_info_cache(app, env, account, container, resp):</p>

<pre><code>"""
Cache info in both memcache and env.

Caching is used to avoid unnecessary calls to account &amp; container servers.
This is a private function that is being called by GETorHEAD_base and
by clear_info_cache.
Any attempt to GET or HEAD from the container/account server should use
the GETorHEAD_base interface which would than set the cache.

:param  app: the application object
:param  account: the unquoted account name
:param  container: the unquoted container name or None
:param resp: the response received or None if info cache should be cleared
"""

if container:
    cache_time = app.recheck_container_existence
else:
    cache_time = app.recheck_account_existence
cache_key, env_key = _get_cache_key(account, container)

if resp:
    if resp.status_int == HTTP_NOT_FOUND:
        cache_time *= 0.1
    elif not is_success(resp.status_int):
        cache_time = None
else:
    cache_time = None

# Next actually set both memcache and the env chache
memcache = getattr(app, 'memcache', None) or env.get('swift.cache')
if not cache_time:
    env.pop(env_key, None)
    if memcache:
        memcache.delete(cache_key)
    return

if container:
    info = headers_to_container_info(resp.headers, resp.status_int)
else:
    info = headers_to_account_info(resp.headers, resp.status_int)
if memcache:
    memcache.set(cache_key, info, time=cache_time)
env[env_key] = info
</code></pre>

<p>{% endcodeblock %}<br/>
* 信息在缓存和env都各存一份，缓存一般用来避免对account和container没必要的调用，这是一个私有方法，主要被GETorHEAD_base和clear_info_cache方法调用。如果想通过HEAD和GET获取container/account信息，建议使用GETorHEAD_base方法，因为该方法会设置缓存信息。
* 检查container和account是否存在，再通过account和container获取缓存key。
* 根据response状态码设置缓存时间，如果缓存时间设置为None，则在env和缓存中移除cache_key缓存信息。
* 最后在缓存和env中设置container或account的info信息。</p>

<h3>_set_object_info_cache</h3>

<p>{% codeblock lang:python %}
def _set_object_info_cache(app, env, account, container, obj, resp):</p>

<pre><code>"""
Cache object info env. Do not cache object informations in
memcache. This is an intentional omission as it would lead
to cache pressure. This is a per-request cache.

Caching is used to avoid unnecessary calls to object servers.
This is a private function that is being called by GETorHEAD_base.
Any attempt to GET or HEAD from the object server should use
the GETorHEAD_base interface which would then set the cache.

:param  app: the application object
:param  account: the unquoted account name
:param  container: the unquoted container name or None
:param  object: the unquoted object name or None
:param resp: the response received or None if info cache should be cleared
"""

env_key = get_object_env_key(account, container, obj)

if not resp:
    env.pop(env_key, None)
    return

info = headers_to_object_info(resp.headers, resp.status_int)
env[env_key] = info
</code></pre>

<p>{% endcodeblock %}<br/>
* object的信息只缓存在env中，没有缓存在memcache中是因为缓存起来的话会对缓存造成压力，这是前一次请求的缓存。缓存为了避免那些对object没必要的调用，这是一个私有方法，主要被GETorHEAD_base和clear_info_cache方法调用。如果想通过HEAD和GET获取container/account信息，建议使用GETorHEAD_base方法，因为该方法会设置缓存信息。
* 先获取object的env_key，如果response没有则在env中移除env_key的信息，最后在env中添加object的info信息。</p>

<h3>clear_info_cache</h3>

<p>{% codeblock lang:python %}
def clear_info_cache(app, env, account, container=None):</p>

<pre><code>"""
Clear the cached info in both memcache and env

:param  app: the application object
:param  account: the account name
:param  container: the containr name or None if setting info for containers
"""
_set_info_cache(app, env, account, container, None)
</code></pre>

<p>{% endcodeblock %}<br/>
* 在memcache和env中清除account或container的缓存信息。</p>

<h3>_get_info_cache</h3>

<p>{% codeblock lang:python %}
def _get_info_cache(app, env, account, container=None):</p>

<pre><code>"""
Get the cached info from env or memcache (if used) in that order
Used for both account and container info
A private function used by get_info

:param  app: the application object
:param  env: the environment used by the current request
:returns the cached info or None if not cached
"""

cache_key, env_key = _get_cache_key(account, container)
if env_key in env:
    return env[env_key]
memcache = getattr(app, 'memcache', None) or env.get('swift.cache')
if memcache:
    info = memcache.get(cache_key)
    if info:
        for key in info:
            if isinstance(info[key], unicode):
                info[key] = info[key].encode("utf-8")
        env[env_key] = info
    return info
return Noner, None)
</code></pre>

<p>{% endcodeblock %}<br/>
* 私有方法，被get_info调用，在env和memcache中获取account和container信息，顺序是先env再memcache。
* 获取env_key和cache_keyi，如果env_key在env中存在，则返回env中的值。
* 如果env中没有，再从memcache中获取信息，将获取到的信息放到env中。</p>

<h3>_prepare_pre_auth_info_request</h3>

<p>{% codeblock lang:python %}
def _prepare_pre_auth_info_request(env, path, swift_source):</p>

<pre><code>"""
Prepares a pre authed request to obtain info using a HEAD.

:param env: the environment used by the current request
:param path: The unquoted request path
:param swift_source: value for swift.source in WSGI environment
:returns: the pre authed request
"""
# Set the env for the pre_authed call without a query string
newenv = make_pre_authed_env(env, 'HEAD', path, agent='Swift',
                             query_string='', swift_source=swift_source)
# This is a sub request for container metadata- drop the Origin header from
# the request so the it is not treated as a CORS request.
newenv.pop('HTTP_ORIGIN', None)
# Note that Request.blank expects quoted path
return Request.blank(quote(path), environ=newenv)
</code></pre>

<p>{% endcodeblock %}<br/>
* 准备一个做过认证的HEAD请求来获取信息。</p>

<h3>get_info</h3>

<p>{% codeblock lang:python %}
def get_info(app, env, account, container=None, ret_not_found=False,</p>

<pre><code>         swift_source=None):
"""
Get the info about accounts or containers

Note: This call bypasses auth. Success does not imply that the
      request has authorization to the info.

:param app: the application object
:param env: the environment used by the current request
:param account: The unquoted name of the account
:param container: The unquoted name of the container (or None if account)
:returns: the cached info or None if cannot be retrieved
"""
info = _get_info_cache(app, env, account, container)
if info:
    if ret_not_found or is_success(info['status']):
        return info
    return None
# Not in cache, let's try the account servers
path = '/v1/%s' % account
if container:
    # Stop and check if we have an account?
    if not get_info(app, env, account):
        return None
    path += '/' + container

req = _prepare_pre_auth_info_request(
    env, path, (swift_source or 'GET_INFO'))
# Whenever we do a GET/HEAD, the GETorHEAD_base will set the info in
# the environment under environ[env_key] and in memcache. We will
# pick the one from environ[env_key] and use it to set the caller env
resp = req.get_response(app)
cache_key, env_key = _get_cache_key(account, container)
try:
    info = resp.environ[env_key]
    env[env_key] = info
    if ret_not_found or is_success(info['status']):
        return info
except (KeyError, AttributeError):
    pass
return None
</code></pre>

<p>{% endcodeblock %}<br/>
* 从缓存中获取info信息，如果缓存中有且状态是success，则返回info。如果缓存没有，则发起1个不用认证的请求获取account和container的info信息。</p>

<h3>_get_object_info</h3>

<p>{% codeblock lang:python %}
def _get_object_info(app, env, account, container, obj, swift_source=None):</p>

<pre><code>"""
Get the info about object

Note: This call bypasses auth. Success does not imply that the
      request has authorization to the info.

:param app: the application object
:param env: the environment used by the current request
:param account: The unquoted name of the account
:param container: The unquoted name of the container
:param obj: The unquoted name of the object
:returns: the cached info or None if cannot be retrieved
"""
env_key = get_object_env_key(account, container, obj)
info = env.get(env_key)
if info:
    return info
# Not in cached, let's try the object servers
path = '/v1/%s/%s/%s' % (account, container, obj)
req = _prepare_pre_auth_info_request(env, path, swift_source)
# Whenever we do a GET/HEAD, the GETorHEAD_base will set the info in
# the environment under environ[env_key]. We will
# pick the one from environ[env_key] and use it to set the caller env
resp = req.get_response(app)
try:
    info = resp.environ[env_key]
    env[env_key] = info
    return info
except (KeyError, AttributeError):
    pass
return None
</code></pre>

<p>{% endcodeblock %}<br/>
* 先从env中获取object的info信息，如果没有则发起请求不认证的请求重新获取。</p>

<h3>close_swift_conn</h3>

<p>{% codeblock lang:python %}
def close_swift_conn(src):</p>

<pre><code>"""
Force close the http connection to the backend.

:param src: the response from the backend
"""
try:
    # Since the backends set "Connection: close" in their response
    # headers, the response object (src) is solely responsible for the
    # socket. The connection object (src.swift_conn) has no references
    # to the socket, so calling its close() method does nothing, and
    # therefore we don't do it.
    #
    # Also, since calling the response's close() method might not
    # close the underlying socket but only decrement some
    # reference-counter, we have a special method here that really,
    # really kills the underlying socket with a close() syscall.
    src.nuke_from_orbit()  # it's the only way to be sure
except Exception:
    pass
</code></pre>

<p>{% endcodeblock %}<br/>
* 关闭swift连接，用了很底层的一个关闭socket连接的方法。</p>

<h2>GetOrHeadHandler类</h2>

<h3>init方法</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def __init__(self, app, req, server_type, ring, partition, path,
             backend_headers):
    self.app = app
    self.ring = ring
    self.server_type = server_type
    self.partition = partition
    self.path = path
    self.backend_headers = backend_headers
    self.used_nodes = []
    self.used_source_etag = ''

    # stuff from request
    self.req_method = req.method
    self.req_path = req.path
    self.req_query_string = req.query_string
    self.newest = config_true_value(req.headers.get('x-newest', 'f'))

    # populated when finding source
    self.statuses = []
    self.reasons = []
    self.bodies = []
    self.source_headers = []
</code></pre>

<p>{% endcodeblock %}<br/>
* GetOrHeadHandler类的初始化方法。</p>

<h3>fast_forward</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def fast_forward(self, num_bytes):
    """
    Will skip num_bytes into the current ranges.

    :params num_bytes: the number of bytes that have already been read on
                       this request. This will change the Range header
                       so that the next req will start where it left off.

    :raises NotImplementedError: if this is a multirange request
    :raises ValueError: if invalid range header
    :raises HTTPRequestedRangeNotSatisfiable: if begin + num_bytes
                                              &gt; end of range
    """
    if 'Range' in self.backend_headers:
        req_range = Range(self.backend_headers['Range'])

        if len(req_range.ranges) &gt; 1:
            raise NotImplementedError()
        begin, end = req_range.ranges.pop()
        if begin is None:
            # this is a -50 range req (last 50 bytes of file)
            end -= num_bytes
        else:
            begin += num_bytes
        if end and begin &gt; end:
            raise HTTPRequestedRangeNotSatisfiable()
        req_range.ranges = [(begin, end)]
        self.backend_headers['Range'] = str(req_range)
    else:
        self.backend_headers['Range'] = 'bytes=%d-' % num_bytes
</code></pre>

<p>{% endcodeblock %}<br/>
* 先判断Range是否在后台进程的header中，如果没有，则在后台进程header中增加Range，值为'bytes=&lsquo;加num_bytes。<br/>
* 如果有，先创建一个Range对象，判断如果Range对象的ranges如果大于1,则报NotImplementedError的异常。<br/>
* 从rangs中取到开始和结束字节数，先检查两个字节数是否正确，不正确抛异常，正确的话将其重新放入到后台进程header中。</p>

<h3>is_good_source</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def is_good_source(self, src):
    """
    Indicates whether or not the request made to the backend found
    what it was looking for.

    :param src: the response from the backend
    :returns: True if found, False if not
    """
    if self.server_type == 'Object' and src.status == 416:
        return True
    return is_success(src.status) or is_redirection(src.status)
</code></pre>

<p>{% endcodeblock %}<br/>
* 如果是一个Object请求，并且返回状态码是416，则返回True，否则返回状态码是否200～399。</p>

<h3>_make_app_iter</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def _make_app_iter(self, req, node, source):
    """
    Returns an iterator over the contents of the source (via its read
    func).  There is also quite a bit of cleanup to ensure garbage
    collection works and the underlying socket of the source is closed.

    :param req: incoming request object
    :param source: The httplib.Response object this iterator should read
                   from.
    :param node: The node the source is reading from, for logging purposes.
    """
    try:
        nchunks = 0
        bytes_read_from_source = 0
        node_timeout = self.app.node_timeout
        if self.server_type == 'Object':
            node_timeout = self.app.recoverable_node_timeout
</code></pre>

<p>{% endcodeblock %}<br/>
* 初始化本地变量，如果是object请求，则将节点超时时间设置为object的recoverable_node_timeout。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        while True:
            try:
                with ChunkReadTimeout(node_timeout):
                    chunk = source.read(self.app.object_chunk_size)
                    nchunks += 1
                    bytes_read_from_source += len(chunk)
            except ChunkReadTimeout:
                exc_type, exc_value, exc_traceback = exc_info()
                if self.newest or self.server_type != 'Object':
                    raise exc_type, exc_value, exc_traceback
                try:
                    self.fast_forward(bytes_read_from_source)
                except (NotImplementedError, HTTPException, ValueError):
                    raise exc_type, exc_value, exc_traceback
                new_source, new_node = self._get_source_and_node()
                if new_source:
                    self.app.exception_occurred(
                        node, _('Object'),
                        _('Trying to read during GET (retrying)'))
                    # Close-out the connection as best as possible.
                    if getattr(source, 'swift_conn', None):
                        close_swift_conn(source)
                    source = new_source
                    node = new_node
                    bytes_read_from_source = 0
                    continue
                else:
                    raise exc_type, exc_value, exc_traceback
            if not chunk:
                break
            with ChunkWriteTimeout(self.app.client_timeout):
                yield chunk                        
</code></pre>

<p>{% endcodeblock %}<br/>
* 通过一个无限循环，不断读取response的数据，累加读取的块数大小和字节总长度。
* 如果读取数据超时，则处理异常，如果请求不是Object则抛出最近的异常信息。
* 记录已读的字节范围，错误抛异常。
* 获取新的source和节点，如果source存在的话，则创建一个异常并关闭连接重新初始化，否则抛出异常。
* 如果读取不到数据，则跳出循环。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>            # This is for fairness; if the network is outpacing the CPU,
            # we'll always be able to read and write data without
            # encountering an EWOULDBLOCK, and so eventlet will not switch
            # greenthreads on its own. We do it manually so that clients
            # don't starve.
            #
            # The number 5 here was chosen by making stuff up. It's not
            # every single chunk, but it's not too big either, so it seemed
            # like it would probably be an okay choice.
            #
            # Note that we may trampoline to other greenthreads more often
            # than once every 5 chunks, depending on how blocking our
            # network IO is; the explicit sleep here simply provides a
            # lower bound on the rate of trampolining.
            if nchunks % 5 == 0:
                sleep()

    except ChunkReadTimeout:
        self.app.exception_occurred(node, _('Object'),
                                    _('Trying to read during GET'))
        raise
    except ChunkWriteTimeout:
        self.app.logger.warn(
            _('Client did not read from proxy within %ss') %
            self.app.client_timeout)
        self.app.logger.increment('client_timeouts')
    except GeneratorExit:
        if not req.environ.get('swift.non_client_disconnect'):
            self.app.logger.warn(_('Client disconnected on read'))
    except Exception:
        self.app.logger.exception(_('Trying to send to client'))
        raise
    finally:
        # Close-out the connection as best as possible.
        if getattr(source, 'swift_conn', None):
            close_swift_conn(source)
</code></pre>

<p>{% endcodeblock %}<br/>
* 每读取5个字节块，休眠一次。
* 读取数据超时抛异常。
* 写入数据超时记日志。
* 抛出各种异常后关闭连接。</p>

<h3>_get_source_and_node</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def _get_source_and_node(self):
    self.statuses = []
    self.reasons = []
    self.bodies = []
    self.source_headers = []
    sources = []

    node_timeout = self.app.node_timeout
    if self.server_type == 'Object' and not self.newest:
        node_timeout = self.app.recoverable_node_timeout
</code></pre>

<p>{% endcodeblock %}<br/>
* 初始化本地变量，设置node_timeout时间。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>    for node in self.app.iter_nodes(self.ring, self.partition):
        if node in self.used_nodes:
            continue
        start_node_timing = time.time()
        try:
            with ConnectionTimeout(self.app.conn_timeout):
                conn = http_connect(
                    node['ip'], node['port'], node['device'],
                    self.partition, self.req_method, self.path,
                    headers=self.backend_headers,
                    query_string=self.req_query_string)
            self.app.set_node_timing(node, time.time() - start_node_timing)

            with Timeout(node_timeout):
                possible_source = conn.getresponse()
                # See NOTE: swift_conn at top of file about this.
                possible_source.swift_conn = conn
        except (Exception, Timeout):
            self.app.exception_occurred(
                node, self.server_type,
                _('Trying to %(method)s %(path)s') %
                {'method': self.req_method, 'path': self.req_path})
            continue
</code></pre>

<p>{% endcodeblock %}<br/>
* 循环取节点，如果节点已经被使用了，则跳过该节点，否则封装http连接，设置节点时间。
* 获取请求结果，如果超时，则抛异常，跳出此次循环。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        if self.is_good_source(possible_source):
            # 404 if we know we don't have a synced copy
            if not float(possible_source.getheader('X-PUT-Timestamp', 1)):
                self.statuses.append(HTTP_NOT_FOUND)
                self.reasons.append('')
                self.bodies.append('')
                self.source_headers.append('')
                close_swift_conn(possible_source)
            else:
                if self.used_source_etag:
                    src_headers = dict(
                        (k.lower(), v) for k, v in
                        possible_source.getheaders())
                    if src_headers.get('etag', '').strip('"') != \
                            self.used_source_etag:
                        self.statuses.append(HTTP_NOT_FOUND)
                        self.reasons.append('')
                        self.bodies.append('')
                        self.source_headers.append('')
                        continue

                self.statuses.append(possible_source.status)
                self.reasons.append(possible_source.reason)
                self.bodies.append('')
                self.source_headers.append('')
                sources.append((possible_source, node))
                if not self.newest:  # one good source is enough
                    break
</code></pre>

<p>{% endcodeblock %}<br/>
* 如果返回结果合理，则判断返回结果中的PUT时间是否存在，不存在证明还没有同步，则返回404并关闭连接。
* 如果时间存在，则继续判断已用etag是否存在，存在的话从返回结果中取出etag值与之比较，不相等就返回404并关闭连接。
* 已用etag不存在，则将返回结果设置到自身属性中，并判断是否最新，是则跳出循环，取一个good source就足够了。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        else:
            self.statuses.append(possible_source.status)
            self.reasons.append(possible_source.reason)
            self.bodies.append(possible_source.read())
            self.source_headers.append(possible_source.getheaders())
            if possible_source.status == HTTP_INSUFFICIENT_STORAGE:
                self.app.error_limit(node, _('ERROR Insufficient Storage'))
            elif is_server_error(possible_source.status):
                self.app.error_occurred(
                    node, _('ERROR %(status)d %(body)s '
                            'From %(type)s Server') %
                    {'status': possible_source.status,
                     'body': self.bodies[-1][:1024],
                     'type': self.server_type})

    if sources:
        sources.sort(key=lambda s: source_key(s[0]))
        source, node = sources.pop()
        for src, _junk in sources:
            close_swift_conn(src)
        self.used_nodes.append(node)
        src_headers = dict(
            (k.lower(), v) for k, v in
            possible_source.getheaders())
        self.used_source_etag = src_headers.get('etag', '').strip('"')
        return source, node
    return None, None
</code></pre>

<p>{% endcodeblock %}<br/>
* 如果返回结果不是一个good source，则将返回结果信息设置到自身属性，如果返回状态是507,则将节点加入到错误列表，如果返回状态是其他500以上的数字，则抛出异常。
* 循环结束后，如果取到了source，则先将sources进行排序然后取第一个，接着关闭剩下的source。
* 添加节点到已用节点，设置易用etag，返回结果，如果取不到source，则返回空。</p>

<h3>get_working_response</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def get_working_response(self, req):
    source, node = self._get_source_and_node()
    res = None
    if source:
        res = Response(request=req)
        if req.method == 'GET' and \
                source.status in (HTTP_OK, HTTP_PARTIAL_CONTENT):
            res.app_iter = self._make_app_iter(req, node, source)
            # See NOTE: swift_conn at top of file about this.
            res.swift_conn = source.swift_conn
        res.status = source.status
        update_headers(res, source.getheaders())
        if not res.environ:
            res.environ = {}
        res.environ['swift_x_timestamp'] = \
            source.getheader('x-timestamp')
        res.accept_ranges = 'bytes'
        res.content_length = source.getheader('Content-Length')
        if source.getheader('Content-Type'):
            res.charset = None
            res.content_type = source.getheader('Content-Type')
    return res
</code></pre>

<p>{% endcodeblock %}
* 先获取source和node，如果有的话，则根据req参数封装response，如果请求是'GET'并且source的状态是200或206,则设置response的app_iter和conn。
* 将source的状态码和header设置进response，再分别根据source的内容设置返回的response的值。</p>

<h2>Controller类</h2>

<h3>init方法</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>"""Base WSGI controller class for the proxy"""
server_type = 'Base'

# Ensure these are all lowercase
pass_through_headers = []

def __init__(self, app):
    """
    Creates a controller attached to an application instance

    :param app: the application instance
    """
    self.account_name = None
    self.app = app
    self.trans_id = '-'
    self._allowed_methods = None
</code></pre>

<p>{% endcodeblock %}<br/>
* 设置类型为base，初始化方法，创建controller时使用。</p>

<h3>allowed_methods</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>@property
def allowed_methods(self):
    if self._allowed_methods is None:
        self._allowed_methods = set()
        all_methods = inspect.getmembers(self, predicate=inspect.ismethod)
        for name, m in all_methods:
            if getattr(m, 'publicly_accessible', False):
                self._allowed_methods.add(name)
    return self._allowed_methods
</code></pre>

<p>{% endcodeblock %}<br/>
* 类属性变量allowed_methods的初始化方法。</p>

<h3>transfer_headers</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def transfer_headers(self, src_headers, dst_headers):
    """
    Transfer legal headers from an original client request to dictionary
    that will be used as headers by the backend request

    :param src_headers: A dictionary of the original client request headers
    :param dst_headers: A dictionary of the backend request headers
    """
    st = self.server_type.lower()

    x_remove = 'x-remove-%s-meta-' % st
    dst_headers.update((k.lower().replace('-remove', '', 1), '')
                       for k in src_headers
                       if k.lower().startswith(x_remove) or
                       k.lower() in self._x_remove_headers())

    dst_headers.update((k.lower(), v)
                       for k, v in src_headers.iteritems()
                       if k.lower() in self.pass_through_headers or
                       is_sys_or_user_meta(st, k))
</code></pre>

<p>{% endcodeblock %}<br/>
* 将一个原始客户端请求的遗留header转换为新的header，给后台进程使用。</p>

<h3>transfer_headers</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def generate_request_headers(self, orig_req=None, additional=None,
                             transfer=False):
    """
    Create a list of headers to be used in backend requets

    :param orig_req: the original request sent by the client to the proxy
    :param additional: additional headers to send to the backend
    :param transfer: If True, transfer headers from original client request
    :returns: a dictionary of headers
    """
    # Use the additional headers first so they don't overwrite the headers
    # we require.
    headers = HeaderKeyDict(additional) if additional else HeaderKeyDict()
    if transfer:
        self.transfer_headers(orig_req.headers, headers)
    headers.setdefault('x-timestamp', normalize_timestamp(time.time()))
    if orig_req:
        referer = orig_req.as_referer()
    else:
        referer = ''
    headers['x-trans-id'] = self.trans_id
    headers['connection'] = 'close'
    headers['user-agent'] = 'proxy-server %s' % os.getpid()
    headers['referer'] = referer
    return headers
</code></pre>

<p>{% endcodeblock %}<br/>
* 生成一组headers为后台进程使用。</p>

<h3>account_info</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def account_info(self, account, req=None):
    """
    Get account information, and also verify that the account exists.

    :param account: name of the account to get the info for
    :param req: caller's HTTP request context object (optional)
    :returns: tuple of (account partition, account nodes, container_count)
              or (None, None, None) if it does not exist
    """
    partition, nodes = self.app.account_ring.get_nodes(account)
    if req:
        env = getattr(req, 'environ', {})
    else:
        env = {}
    info = get_info(self.app, env, account)
    if not info:
        return None, None, None
    if info.get('container_count') is None:
        container_count = 0
    else:
        container_count = int(info['container_count'])
    return partition, nodes, container_count
</code></pre>

<p>{% endcodeblock %}<br/>
* 获取account信息，正常返回分区号，节点和容器数量，获取不到返回3个None。</p>

<h3>account_info</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def container_info(self, account, container, req=None):
    """
    Get container information and thusly verify container existence.
    This will also verify account existence.

    :param account: account name for the container
    :param container: container name to look up
    :param req: caller's HTTP request context object (optional)
    :returns: dict containing at least container partition ('partition'),
              container nodes ('containers'), container read
              acl ('read_acl'), container write acl ('write_acl'),
              and container sync key ('sync_key').
              Values are set to None if the container does not exist.
    """
    part, nodes = self.app.container_ring.get_nodes(account, container)
    if req:
        env = getattr(req, 'environ', {})
    else:
        env = {}
    info = get_info(self.app, env, account, container)
    if not info:
        info = headers_to_container_info({}, 0)
        info['partition'] = None
        info['nodes'] = None
    else:
        info['partition'] = part
        info['nodes'] = nodes
    return info
</code></pre>

<p>{% endcodeblock %}<br/>
* 获取container信息，会顺便校验container是否存在，也会校验account是否存在。</p>

<h3>make_request(私有方法)</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def _make_request(self, nodes, part, method, path, headers, query,
                  logger_thread_locals):
    """
    Iterates over the given node iterator, sending an HTTP request to one
    node at a time.  The first non-informational, non-server-error
    response is returned.  If no non-informational, non-server-error
    response is received from any of the nodes, returns None.

    :param nodes: an iterator of the backend server and handoff servers
    :param part: the partition number
    :param method: the method to send to the backend
    :param path: the path to send to the backend
                 (full path ends up being /&lt;$device&gt;/&lt;$part&gt;/&lt;$path&gt;)
    :param headers: a list of dicts, where each dict represents one
                    backend request that should be made.
    :param query: query string to send to the backend.
    :param logger_thread_locals: The thread local values to be set on the
                                 self.app.logger to retain transaction
                                 logging information.
    :returns: a swob.Response object, or None if no responses were received
    """
    self.app.logger.thread_locals = logger_thread_locals
    for node in nodes:
        try:
            start_node_timing = time.time()
            with ConnectionTimeout(self.app.conn_timeout):
                conn = http_connect(node['ip'], node['port'],
                                    node['device'], part, method, path,
                                    headers=headers, query_string=query)
                conn.node = node
            self.app.set_node_timing(node, time.time() - start_node_timing)
            with Timeout(self.app.node_timeout):
                resp = conn.getresponse()
                if not is_informational(resp.status) and \
                        not is_server_error(resp.status):
                    return resp.status, resp.reason, resp.getheaders(), \
                        resp.read()
                elif resp.status == HTTP_INSUFFICIENT_STORAGE:
                    self.app.error_limit(node,
                                         _('ERROR Insufficient Storage'))
        except (Exception, Timeout):
            self.app.exception_occurred(
                node, self.server_type,
                _('Trying to %(method)s %(path)s') %
                {'method': method, 'path': path})
</code></pre>

<p>{% endcodeblock %}<br/>
* 遍历每个节点，根据节点信息发起请求，如果请求不是100+和500+，则返回请求结果。
* 如果请求状态码为507，则加入node到异常node列表。
* 其他异常抛出异常信息。</p>

<h3>make_requests</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def make_requests(self, req, ring, part, method, path, headers,
                  query_string=''):
    """
    Sends an HTTP request to multiple nodes and aggregates the results.
    It attempts the primary nodes concurrently, then iterates over the
    handoff nodes as needed.

    :param req: a request sent by the client
    :param ring: the ring used for finding backend servers
    :param part: the partition number
    :param method: the method to send to the backend
    :param path: the path to send to the backend
                 (full path ends up being  /&lt;$device&gt;/&lt;$part&gt;/&lt;$path&gt;)
    :param headers: a list of dicts, where each dict represents one
                    backend request that should be made.
    :param query_string: optional query string to send to the backend
    :returns: a swob.Response object
    """
    start_nodes = ring.get_part_nodes(part)
    nodes = GreenthreadSafeIterator(self.app.iter_nodes(ring, part))
    pile = GreenAsyncPile(len(start_nodes))
    for head in headers:
        pile.spawn(self._make_request, nodes, part, method, path,
                   head, query_string, self.app.logger.thread_locals)
    response = []
    statuses = []
    for resp in pile:
        if not resp:
            continue
        response.append(resp)
        statuses.append(resp[0])
        if self.have_quorum(statuses, len(start_nodes)):
            break
    # give any pending requests *some* chance to finish
    pile.waitall(self.app.post_quorum_timeout)
    while len(response) &lt; len(start_nodes):
        response.append((HTTP_SERVICE_UNAVAILABLE, '', '', ''))
    statuses, reasons, resp_headers, bodies = zip(*response)
    return self.best_response(req, statuses, reasons, bodies,
                              '%s %s' % (self.server_type, req.method),
                              headers=resp_headers)
</code></pre>

<p>{% endcodeblock %}<br/>
* 先通过partition获取node节点，再根据节点个数创建线程发起每个节点请求。
* 获取每个线程的返回结果，将状态码和响应结果记录保存到列表中，如果状态码列表个数超过节点的一半，则跳出循环。
* 将剩下的response设置为503，最后通过best_response方法获取response。</p>

<h3>have_quorum</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def have_quorum(self, statuses, node_count):
    """
    Given a list of statuses from several requests, determine if
    a quorum response can already be decided.

    :param statuses: list of statuses returned
    :param node_count: number of nodes being queried (basically ring count)
    :returns: True or False, depending on if quorum is established
    """
    quorum = quorum_size(node_count)
    if len(statuses) &gt;= quorum:
        for hundred in (HTTP_OK, HTTP_MULTIPLE_CHOICES, HTTP_BAD_REQUEST):
            if sum(1 for s in statuses
                   if hundred &lt;= s &lt; hundred + 100) &gt;= quorum:
                return True
    return False
</code></pre>

<p>{% endcodeblock %}<br/>
* 通过节点个数和一组状态码判断响应是否已经满足限额。</p>

<h3>best_response</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def best_response(self, req, statuses, reasons, bodies, server_type,
                  etag=None, headers=None):
    """
    Given a list of responses from several servers, choose the best to
    return to the API.

    :param req: swob.Request object
    :param statuses: list of statuses returned
    :param reasons: list of reasons for each status
    :param bodies: bodies of each response
    :param server_type: type of server the responses came from
    :param etag: etag
    :param headers: headers of each response
    :returns: swob.Response object with the correct status, body, etc. set
    """
    resp = Response(request=req)
    if len(statuses):
        for hundred in (HTTP_OK, HTTP_MULTIPLE_CHOICES, HTTP_BAD_REQUEST):
            hstatuses = \
                [s for s in statuses if hundred &lt;= s &lt; hundred + 100]
            if len(hstatuses) &gt;= quorum_size(len(statuses)):
                status = max(hstatuses)
                status_index = statuses.index(status)
                resp.status = '%s %s' % (status, reasons[status_index])
                resp.body = bodies[status_index]
                if headers:
                    update_headers(resp, headers[status_index])
                if etag:
                    resp.headers['etag'] = etag.strip('"')
                return resp
    self.app.logger.error(_('%(type)s returning 503 for %(statuses)s'),
                          {'type': server_type, 'statuses': statuses})
    resp.status = '503 Internal Server Error'
    return resp
</code></pre>

<p>{% endcodeblock %}<br/>
* 给定一组response，返回最佳的response。
* 比如副本数是3,response列表是[201,201,503],则返回201。</p>

<h3>autocreate_account</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def autocreate_account(self, env, account):
    """
    Autocreate an account

    :param env: the environment of the request leading to this autocreate
    :param account: the unquoted account name
    """
    partition, nodes = self.app.account_ring.get_nodes(account)
    path = '/%s' % account
    headers = {'X-Timestamp': normalize_timestamp(time.time()),
               'X-Trans-Id': self.trans_id,
               'Connection': 'close'}
    resp = self.make_requests(Request.blank('/v1' + path),
                              self.app.account_ring, partition, 'PUT',
                              path, [headers] * len(nodes))
    if is_success(resp.status_int):
        self.app.logger.info('autocreate account %r' % path)
        clear_info_cache(self.app, env, account)
    else:
        self.app.logger.warning('Could not autocreate account %r' % path)
</code></pre>

<p>{% endcodeblock %}<br/>
* 发起一个PUT请求自动创建account，创建失败记录警告信息。</p>

<h3>GETorHEAD_base</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def GETorHEAD_base(self, req, server_type, ring, partition, path):
    """
    Base handler for HTTP GET or HEAD requests.

    :param req: swob.Request object
    :param server_type: server type used in logging
    :param ring: the ring to obtain nodes from
    :param partition: partition
    :param path: path for the request
    :returns: swob.Response object
    """
    backend_headers = self.generate_request_headers(
        req, additional=req.headers)

    handler = GetOrHeadHandler(self.app, req, self.server_type, ring,
                               partition, path, backend_headers)
    res = handler.get_working_response(req)

    if not res:
        res = self.best_response(
            req, handler.statuses, handler.reasons, handler.bodies,
            '%s %s' % (server_type, req.method),
            headers=handler.source_headers)
    try:
        (vrs, account, container) = req.split_path(2, 3)
        _set_info_cache(self.app, req.environ, account, container, res)
    except ValueError:
        pass
    try:
        (vrs, account, container, obj) = req.split_path(4, 4, True)
        _set_object_info_cache(self.app, req.environ, account,
                               container, obj, res)
    except ValueError:
        pass
    return res
</code></pre>

<p>{% endcodeblock %}<br/>
* 基类controller的get或head请求处理方法，首先构造header和handler发起一个http请求。
* 如果请求没有响应，则调用best_response方法取到response。
* 如果请求有响应，则根据request分割出account、container和object信息，设置到缓存中，最后返回response。</p>

<h3>is_origin_allowed</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def is_origin_allowed(self, cors_info, origin):
    """
    Is the given Origin allowed to make requests to this resource

    :param cors_info: the resource's CORS related metadata headers
    :param origin: the origin making the request
    :return: True or False
    """
    allowed_origins = set()
    if cors_info.get('allow_origin'):
        allowed_origins.update(
            [a.strip()
             for a in cors_info['allow_origin'].split(' ')
             if a.strip()])
    if self.app.cors_allow_origin:
        allowed_origins.update(self.app.cors_allow_origin)
    return origin in allowed_origins or '*' in allowed_origins
</code></pre>

<p>{% endcodeblock %}<br/>
* 判断该请求方法是否允许发起请求，先从header中获取'allow_origin'的值，如果有的花，更新允许访问列表。
* 如果原请求方法在允许访问列表中，或者允许访问列表中有'*&lsquo;，则返回True。</p>

<h3>OPTIONS</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>@public
def OPTIONS(self, req):
    """
    Base handler for OPTIONS requests

    :param req: swob.Request object
    :returns: swob.Response object
    """
    # Prepare the default response
    headers = {'Allow': ', '.join(self.allowed_methods)}
    resp = Response(status=200, request=req, headers=headers)

    # If this isn't a CORS pre-flight request then return now
    req_origin_value = req.headers.get('Origin', None)
    if not req_origin_value:
        return resp
</code></pre>

<p>{% endcodeblock %}<br/>
* options请求的基本handler，准备一个默认的response，如果不是一个CORS请求，则返回默认的response。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>    # This is a CORS preflight request so check it's allowed
    try:
        container_info = \
            self.container_info(self.account_name,
                                self.container_name, req)
    except AttributeError:
        # This should only happen for requests to the Account. A future
        # change could allow CORS requests to the Account level as well.
        return resp

    cors = container_info.get('cors', {})

    # If the CORS origin isn't allowed return a 401
    if not self.is_origin_allowed(cors, req_origin_value) or (
            req.headers.get('Access-Control-Request-Method') not in
            self.allowed_methods):
        resp.status = HTTP_UNAUTHORIZED
        return resp
</code></pre>

<p>{% endcodeblock %}<br/>
* 如果对account进行操作的CORS请求，则返回默认reponse，否则获取container信息。
* 如果CORS请求不允许，则返回401。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>    # Allow all headers requested in the request. The CORS
    # specification does leave the door open for this, as mentioned in
    # http://www.w3.org/TR/cors/#resource-preflight-requests
    # Note: Since the list of headers can be unbounded
    # simply returning headers can be enough.
    allow_headers = set()
    if req.headers.get('Access-Control-Request-Headers'):
        allow_headers.update(
            list_from_csv(req.headers['Access-Control-Request-Headers']))

    # Populate the response with the CORS preflight headers
    if cors.get('allow_origin', '').strip() == '*':
        headers['access-control-allow-origin'] = '*'
    else:
        headers['access-control-allow-origin'] = req_origin_value
    if cors.get('max_age') is not None:
        headers['access-control-max-age'] = cors.get('max_age')
    headers['access-control-allow-methods'] = \
        ', '.join(self.allowed_methods)
    if allow_headers:
        headers['access-control-allow-headers'] = ', '.join(allow_headers)
    resp.headers = headers

    return resp
</code></pre>

<p>{% endcodeblock %}<br/>
* 在response的header中增加相关header，分别有'access-control-allow-origin',&lsquo;access-control-max-age&rsquo;,&lsquo;access-control-allow-methods'和'access-control-allow-headers'。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[swift源码详解（二）——proxy/server.py]]></title>
    <link href="http://zhaozhiming.github.io/blog/2014/04/20/swift-code-explain-proxy-server/"/>
    <updated>2014-04-20T20:52:00+08:00</updated>
    <id>http://zhaozhiming.github.io/blog/2014/04/20/swift-code-explain-proxy-server</id>
    <content type="html"><![CDATA[<h2><a href="http://zhaozhiming.github.io/blog/2014/04/19/swift-code-explain-total/">回swift代码结构目录</a></h2>

<h3>int方法</h3>

<!--more-->


<p>
{% codeblock lang:python %}</p>

<pre><code>def __init__(self, conf, memcache=None, logger=None, account_ring=None,
             container_ring=None, object_ring=None):
    if conf is None:
        conf = {}
    if logger is None:
        self.logger = get_logger(conf, log_route='proxy-server')
    else:
        self.logger = logger
    swift_dir = conf.get('swift_dir', '/etc/swift')
    self.node_timeout = int(conf.get('node_timeout', 10))
    self.recoverable_node_timeout = int(
        conf.get('recoverable_node_timeout', self.node_timeout))
    self.conn_timeout = float(conf.get('conn_timeout', 0.5))
    self.client_timeout = int(conf.get('client_timeout', 60))
    self.put_queue_depth = int(conf.get('put_queue_depth', 10))
    self.object_chunk_size = int(conf.get('object_chunk_size', 65536))
    self.client_chunk_size = int(conf.get('client_chunk_size', 65536))
    self.trans_id_suffix = conf.get('trans_id_suffix', '')
    self.post_quorum_timeout = float(conf.get('post_quorum_timeout', 0.5))
    self.error_suppression_interval = \
        int(conf.get('error_suppression_interval', 60))
    self.error_suppression_limit = \
        int(conf.get('error_suppression_limit', 10))
    self.recheck_container_existence = \
        int(conf.get('recheck_container_existence', 60))
    self.recheck_account_existence = \
        int(conf.get('recheck_account_existence', 60))
    self.allow_account_management = \
        config_true_value(conf.get('allow_account_management', 'no'))
    self.object_post_as_copy = \
        config_true_value(conf.get('object_post_as_copy', 'true'))
    self.object_ring = object_ring or Ring(swift_dir, ring_name='object')
    self.container_ring = container_ring or Ring(swift_dir,
                                                 ring_name='container')
    self.account_ring = account_ring or Ring(swift_dir,
                                             ring_name='account')
    self.memcache = memcache
    mimetypes.init(mimetypes.knownfiles +
                   [os.path.join(swift_dir, 'mime.types')])
    self.account_autocreate = \
        config_true_value(conf.get('account_autocreate', 'no'))
    self.expiring_objects_account = \
        (conf.get('auto_create_account_prefix') or '.') + \
        (conf.get('expiring_objects_account_name') or 'expiring_objects')
    self.expiring_objects_container_divisor = \
        int(conf.get('expiring_objects_container_divisor') or 86400)
    self.max_containers_per_account = \
        int(conf.get('max_containers_per_account') or 0)
    self.max_containers_whitelist = [
        a.strip()
        for a in conf.get('max_containers_whitelist', '').split(',')
        if a.strip()]
    self.deny_host_headers = [
        host.strip() for host in
        conf.get('deny_host_headers', '').split(',') if host.strip()]
    self.rate_limit_after_segment = \
        int(conf.get('rate_limit_after_segment', 10))
    self.rate_limit_segments_per_sec = \
        int(conf.get('rate_limit_segments_per_sec', 1))
    self.log_handoffs = config_true_value(conf.get('log_handoffs', 'true'))
    self.cors_allow_origin = [
        a.strip()
        for a in conf.get('cors_allow_origin', '').split(',')
        if a.strip()]
    self.strict_cors_mode = config_true_value(
        conf.get('strict_cors_mode', 't'))
    self.node_timings = {}
    self.timing_expiry = int(conf.get('timing_expiry', 300))
    self.sorting_method = conf.get('sorting_method', 'shuffle').lower()
    self.max_large_object_get_time = float(
        conf.get('max_large_object_get_time', '86400'))
    value = conf.get('request_node_count', '2 * replicas').lower().split()
    if len(value) == 1:
        value = int(value[0])
        self.request_node_count = lambda replicas: value
    elif len(value) == 3 and value[1] == '*' and value[2] == 'replicas':
        value = int(value[0])
        self.request_node_count = lambda replicas: value * replicas
    else:
        raise ValueError(
            'Invalid request_node_count value: %r' % ''.join(value))
    try:
        self._read_affinity = read_affinity = conf.get('read_affinity', '')
        self.read_affinity_sort_key = affinity_key_function(read_affinity)
    except ValueError as err:
        # make the message a little more useful
        raise ValueError("Invalid read_affinity value: %r (%s)" %
                         (read_affinity, err.message))

    try:
        write_affinity = conf.get('write_affinity', '')
        self.write_affinity_is_local_fn \
            = affinity_locality_predicate(write_affinity)
    except ValueError as err:
        # make the message a little more useful
        raise ValueError("Invalid write_affinity value: %r (%s)" %
                         (write_affinity, err.message))

    value = conf.get('write_affinity_node_count',
                     '2 * replicas').lower().split()
    if len(value) == 1:
        value = int(value[0])
        self.write_affinity_node_count = lambda replicas: value
    elif len(value) == 3 and value[1] == '*' and value[2] == 'replicas':
        value = int(value[0])
        self.write_affinity_node_count = lambda replicas: value * replicas
    else:
        raise ValueError(
            'Invalid write_affinity_node_count value: %r' % ''.join(value))
    # swift_owner_headers are stripped by the account and container
    # controllers; we should extend header stripping to object controller
    # when a privileged object header is implemented.
    swift_owner_headers = conf.get(
        'swift_owner_headers',
        'x-container-read, x-container-write, '
        'x-container-sync-key, x-container-sync-to, '
        'x-account-meta-temp-url-key, x-account-meta-temp-url-key-2, '
        'x-account-access-control')
    self.swift_owner_headers = [
        name.strip().title()
        for name in swift_owner_headers.split(',') if name.strip()]
    # Initialization was successful, so now apply the client chunk size
    # parameter as the default read / write buffer size for the network
    # sockets.
    #
    # NOTE WELL: This is a class setting, so until we get set this on a
    # per-connection basis, this affects reading and writing on ALL
    # sockets, those between the proxy servers and external clients, and
    # those between the proxy servers and the other internal servers.
    #
    # ** Because it affects the client as well, currently, we use the
    # client chunk size as the govenor and not the object chunk size.
    socket._fileobject.default_bufsize = self.client_chunk_size
    self.expose_info = config_true_value(
        conf.get('expose_info', 'yes'))
    self.disallowed_sections = list_from_csv(
        conf.get('disallowed_sections'))
    self.admin_key = conf.get('admin_key', None)
    register_swift_info(
        version=swift_version,
        strict_cors_mode=self.strict_cors_mode,
        **constraints.EFFECTIVE_CONSTRAINTS)
</code></pre>

<p>{% endcodeblock %}
proxy server的初始化函数，具体配置的说明可以参考<a href="http://docs.openstack.org/havana/config-reference/content/proxy-server-conf.html">这里</a>。</p>

<h3>check_config</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def check_config(self):
    """
    Check the configuration for possible errors
    """
    if self._read_affinity and self.sorting_method != 'affinity':
        self.logger.warn("sorting_method is set to '%s', not 'affinity'; "
                         "read_affinity setting will have no effect." %
                         self.sorting_method)
</code></pre>

<p>{% endcodeblock %}<br/>
proxy server初始化后被调用的方法，检查proxy的read_affinity配置和排序方法设置不一致时，记录警告日志。</p>

<h3>call方法</h3>

<p>{% codeblock lang:python %}
def <strong>call</strong>(self, env, start_response):</p>

<pre><code>    """
    WSGI entry point.
    Wraps env in swob.Request object and passes it down.

    :param env: WSGI environment dictionary
    :param start_response: WSGI callable
    """
    try:
        if self.memcache is None:
            self.memcache = cache_from_env(env)
        req = self.update_request(Request(env))
        return self.handle_request(req)(env, start_response)
    except UnicodeError:
        err = HTTPPreconditionFailed(
            request=req, body='Invalid UTF8 or contains NULL')
        return err(env, start_response)
    except (Exception, Timeout):
        start_response('500 Server Error',
                       [('Content-Type', 'text/plain')])
        return ['Internal server error.\n']
</code></pre>

<p>{% endcodeblock %}<br/>
* 9~10: 检查memcache缓存是否为空，如果为空的话就从上下文中获取，由于proxy-server在pipeline中是最后面，如果pipeline前面配置了memcache中间件的话，就可以从上下文中取到。<br/>
* 12: 调用update_request方法，后面会介绍。<br/>
* 13: 调用handle_request方法，后面会介绍，最后返回response。<br/>
* 14~17: 捕获UnicodeError并返回412。<br/>
* 18~21: 捕获Timeout和其他异常并返回500。</p>

<h3>update_request</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def update_request(self, req):
    if 'x-storage-token' in req.headers and \
            'x-auth-token' not in req.headers:
        req.headers['x-auth-token'] = req.headers['x-storage-token']
    return req
</code></pre>

<p>{% endcodeblock %}<br/>
该方法是将requeset中的x-auth-token的header替换为x-storage-token的header。</p>

<h3>handle_request</h3>

<p>{% codeblock lang:python %}
def handle_request(self, req):</p>

<pre><code>    """
    Entry point for proxy server.
    Should return a WSGI-style callable (such as swob.Response).

    :param req: swob.Request object
    """
    try:
        self.logger.set_statsd_prefix('proxy-server')
        if req.content_length and req.content_length &lt; 0:
            self.logger.increment('errors')
            return HTTPBadRequest(request=req,
                                  body='Invalid Content-Length')

        try:
            if not check_utf8(req.path_info):
                self.logger.increment('errors')
                return HTTPPreconditionFailed(
                    request=req, body='Invalid UTF8 or contains NULL')
        except UnicodeError:
            self.logger.increment('errors')
            return HTTPPreconditionFailed(
                request=req, body='Invalid UTF8 or contains NULL')
</code></pre>

<p>{% endcodeblock %}<br/>
* 8: 在log中设置'proxy-server'前缀。<br/>
* 10~13: 检查request中content length如果有且长度为0，则返回500。<br/>
* 15~23  : 检查url格式是否utf-8，如果不是则返回412。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        try:
            controller, path_parts = self.get_controller(req.path)
            p = req.path_info
            if isinstance(p, unicode):
                p = p.encode('utf-8')
        except ValueError:
            self.logger.increment('errors')
            return HTTPNotFound(request=req)
        if not controller:
            self.logger.increment('errors')
            return HTTPPreconditionFailed(request=req, body='Bad URL')
        if self.deny_host_headers and \
                req.host.split(':')[0] in self.deny_host_headers:
            return HTTPForbidden(request=req, body='Invalid host header')
</code></pre>

<p>{% endcodeblock %}<br/>
* 2～5: 调用get_controller方法(后面会介绍)，通过url获取对应的controller类和url中通过'/&lsquo;符号分割的各个部分。<br/>
* 6~8: 捕获ValueError并返回404。<br/>
* 9~11: 如果controller类为空则返回404。<br/>
* 12~14: 如果proxy中有定义deny_host_headers(禁止访问的ip），并且request的ip与禁止访问的ip一致，则返回403。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        self.logger.set_statsd_prefix('proxy-server.' +
                                      controller.server_type.lower())
        controller = controller(self, **path_parts)
        if 'swift.trans_id' not in req.environ:
            # if this wasn't set by an earlier middleware, set it now
            trans_id = generate_trans_id(self.trans_id_suffix)
            req.environ['swift.trans_id'] = trans_id
            self.logger.txn_id = trans_id
        req.headers['x-trans-id'] = req.environ['swift.trans_id']
        controller.trans_id = req.environ['swift.trans_id']
        self.logger.client_ip = get_remote_client(req)
</code></pre>

<p>{% endcodeblock %}<br/>
* 1～2: 日志加上controller名字前缀。
* 3: 通过controller类实例化controller对象。
* 4~10: 如果swift.trans_id没有在request的上下文中，则重新生成trans_id，并设置在上下文、日志、header和controller中。<br/>
* 11: 调用get_remote_client方法(后面介绍)，先判断header中是否有'x-cluster-client-ip'，如果没有再去获取header中的'x-forwarded-for'，还是没有的话就从request中的remote_addr取值，得到client_ip。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        try:
            handler = getattr(controller, req.method)
            getattr(handler, 'publicly_accessible')
        except AttributeError:
            allowed_methods = getattr(controller, 'allowed_methods', set())
            return HTTPMethodNotAllowed(
                request=req, headers={'Allow': ', '.join(allowed_methods)})
</code></pre>

<p>{% endcodeblock %}<br/>
* 2~3: 通过request的method，在controller得到一个名字相同，并且有'public'标签的方法对象handler。
* 4~7: 如果获取不到对应的public方法，则打印出controller中所有public方法并返回405。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>        if 'swift.authorize' in req.environ:
            # We call authorize before the handler, always. If authorized,
            # we remove the swift.authorize hook so isn't ever called
            # again. If not authorized, we return the denial unless the
            # controller's method indicates it'd like to gather more
            # information and try again later.
            resp = req.environ['swift.authorize'](req)
            if not resp:
                # No resp means authorized, no delayed recheck required.
                del req.environ['swift.authorize']
            else:
                # Response indicates denial, but we might delay the denial
                # and recheck later. If not delayed, return the error now.
                if not getattr(handler, 'delay_denial', None):
                    return resp
</code></pre>

<p>{% endcodeblock %}<br/>
如果request的上下文中有swift.authorize，则调用这个方法进行认证。<br/>
如果没有返回结果证明之前已经认证通过了，后面的请求不需要再认证，将'swift.authorize'从上下文去掉。<br/>
如果有Response返回则表示认证不通过，会先检查是否有延迟禁止的配置，如果没有返回认证不通过的response，如果有则会等后面再重新确认。<br/>
{% codeblock lang:python %}</p>

<pre><code>        # Save off original request method (GET, POST, etc.) in case it
        # gets mutated during handling.  This way logging can display the
        # method the client actually sent.
        req.environ['swift.orig_req_method'] = req.method
        return handler(req)
    except HTTPException as error_response:
        return error_response
    except (Exception, Timeout):
        self.logger.exception(_('ERROR Unhandled exception in request'))
        return HTTPServerError(request=req)
</code></pre>

<p>{% endcodeblock %}<br/>
* 4~5: 在日志中记录原始的request方法，防止请求在传播过程中发生突变http请求方法发生改变。
* 6~10: 捕获异常，记录日志。</p>

<h3>get_controller</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def get_controller(self, path):
    """
    Get the controller to handle a request.

    :param path: path from request
    :returns: tuple of (controller class, path dictionary)

    :raises: ValueError (thrown by split_path) if given invalid path
    """
    if path == '/info':
        d = dict(version=None,
                 expose_info=self.expose_info,
                 disallowed_sections=self.disallowed_sections,
                 admin_key=self.admin_key)
        return InfoController, d

    version, account, container, obj = split_path(path, 1, 4, True)
    d = dict(version=version,
             account_name=account,
             container_name=container,
             object_name=obj)
    if obj and container and account:
        return ObjectController, d
    elif container and account:
        return ContainerController, d
    elif account and not container and not obj:
        return AccountController, d
    return None, d
</code></pre>

<p>{% endcodeblock %}<br/>
* 10～15: 如果url是'info'，则返回InController和controller字典参数，expose_info表示是否暴露信息，disallowed_sections表示不允许暴露的字段列表，比如container_qutoas, tempurl等。
* 17～28: 根据url判断是account、container还是object，返回对应的controller和字典参数。</p>

<h3>sort_nodes</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def sort_nodes(self, nodes):
    '''
    Sorts nodes in-place (and returns the sorted list) according to
    the configured strategy. The default "sorting" is to randomly
    shuffle the nodes. If the "timing" strategy is chosen, the nodes
    are sorted according to the stored timing data.
    '''
    # In the case of timing sorting, shuffling ensures that close timings
    # (ie within the rounding resolution) won't prefer one over another.
    # Python's sort is stable (http://wiki.python.org/moin/HowTo/Sorting/)
    shuffle(nodes)
    if self.sorting_method == 'timing':
        now = time()

        def key_func(node):
            timing, expires = self.node_timings.get(node['ip'], (-1.0, 0))
            return timing if expires &gt; now else -1.0
        nodes.sort(key=key_func)
    elif self.sorting_method == 'affinity':
        nodes.sort(key=self.read_affinity_sort_key)
    return nodes
</code></pre>

<p>{% endcodeblock %}<br/>
节点的排序方法，将节点根据配置的排序策略进行排序。<br/>
* 11: 将节点顺序打乱，确保节点不会按照时间排好序。
* 12～18: 如果配置的排序策略是按时间排序，则定义一个（节点）按时间排序的方法让节点按照这个方法排序，如果节点已过期则timing为-0.1，即会被排到最后。
* 19～20: 如果配置的排序策略是按亲和力排序，则节点按照亲和力方法排序。</p>

<h3>set_node_timing</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def set_node_timing(self, node, timing):
    if self.sorting_method != 'timing':
        return
    now = time()
    timing = round(timing, 3)  # sort timings to the millisecond
    self.node_timings[node['ip']] = (timing, now + self.timing_expiry)
</code></pre>

<p>{% endcodeblock %}<br/>
* 2～3: 如果配置的排序策略不是'timing'，则直接返回不做设置。
* 4～6: 设置单个节点的排序时间过期时间。</p>

<h3>error_limited</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def error_limited(self, node):
    """
    Check if the node is currently error limited.

    :param node: dictionary of node to check
    :returns: True if error limited, False otherwise
    """
    now = time()
    if 'errors' not in node:
        return False
    if 'last_error' in node and node['last_error'] &lt; \
            now - self.error_suppression_interval:
        del node['last_error']
        if 'errors' in node:
            del node['errors']
        return False
    limited = node['errors'] &gt; self.error_suppression_limit
    if limited:
        self.logger.debug(
            _('Node error limited %(ip)s:%(port)s (%(device)s)'), node)
    return limited
</code></pre>

<p>{% endcodeblock %}<br/>
* 8～10: 如果节点里面没有'errors'选项，则返回false。
* 11～10: 如果节点里面的'last_error'选项不正确，则删除该选项和errors选项，并返回false。
* 12～15: 判断节点的错误个数是否超过配置的错误限制，如果超过则记录日志，并返回是否超限制的结果。</p>

<h3>error_limit</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def error_limit(self, node, msg):
    """
    Mark a node as error limited. This immediately pretends the
    node received enough errors to trigger error suppression. Use
    this for errors like Insufficient Storage. For other errors
    use :func:`error_occurred`.

    :param node: dictionary of node to error limit
    :param msg: error message
    """
    node['errors'] = self.error_suppression_limit + 1
    node['last_error'] = time()
    self.logger.error(_('%(msg)s %(ip)s:%(port)s/%(device)s'),
                      {'msg': msg, 'ip': node['ip'],
                      'port': node['port'], 'device': node['device']})
</code></pre>

<p>{% endcodeblock %}<br/>
* 11～14: 记录一个节点的错误信息:错误个数，最后错误的时间，并记录日志。</p>

<h3>error_occurred</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def error_occurred(self, node, msg):
    """
    Handle logging, and handling of errors.

    :param node: dictionary of node to handle errors for
    :param msg: error message
    """
    node['errors'] = node.get('errors', 0) + 1
    node['last_error'] = time()
    self.logger.error(_('%(msg)s %(ip)s:%(port)s/%(device)s'),
                      {'msg': msg, 'ip': node['ip'],
                      'port': node['port'], 'device': node['device']})
</code></pre>

<p>{% endcodeblock %}<br/>
* 8～12: 与前面的方法类似，唯一区别是记录节点错误个数是取当前的错误个数，然后+1。</p>

<h3>iter_nodes</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def iter_nodes(self, ring, partition, node_iter=None):
    """
    Yields nodes for a ring partition, skipping over error
    limited nodes and stopping at the configurable number of
    nodes. If a node yielded subsequently gets error limited, an
    extra node will be yielded to take its place.

    Note that if you're going to iterate over this concurrently from
    multiple greenthreads, you'll want to use a
    swift.common.utils.GreenthreadSafeIterator to serialize access.
    Otherwise, you may get ValueErrors from concurrent access. (You also
    may not, depending on how logging is configured, the vagaries of
    socket IO and eventlet, and the phase of the moon.)

    :param ring: ring to get yield nodes from
    :param partition: ring partition to yield nodes for
    :param node_iter: optional iterable of nodes to try. Useful if you
        want to filter or reorder the nodes.
    """
    part_nodes = ring.get_part_nodes(partition)
    if node_iter is None:
        node_iter = itertools.chain(part_nodes,
                                    ring.get_more_nodes(partition))
    num_primary_nodes = len(part_nodes)

    # Use of list() here forcibly yanks the first N nodes (the primary
    # nodes) from node_iter, so the rest of its values are handoffs.
    primary_nodes = self.sort_nodes(
        list(itertools.islice(node_iter, num_primary_nodes)))
    handoff_nodes = node_iter
    nodes_left = self.request_node_count(len(primary_nodes))
</code></pre>

<p>{% endcodeblock %}<br/>
* 20～24: 根据partition获取相应的节点，如果node_iter为空，则将之前取到的节点和get_more_nodes节点连接起来为node_iter赋值，并取得节点个数。
* 28～31: 将node_iter的节点重新排序，并取前面部分作为主要nodes，handoff_nodes为node_iter剩下的nodes， nodes_left为剩下的节点个数。</p>

<p>{% codeblock lang:python %}</p>

<pre><code>    for node in primary_nodes:
        if not self.error_limited(node):
            yield node
            if not self.error_limited(node):
                nodes_left -= 1
                if nodes_left &lt;= 0:
                    return
    handoffs = 0
    for node in handoff_nodes:
        if not self.error_limited(node):
            handoffs += 1
            if self.log_handoffs:
                self.logger.increment('handoff_count')
                self.logger.warning(
                    'Handoff requested (%d)' % handoffs)
                if handoffs == len(primary_nodes):
                    self.logger.increment('handoff_all_count')
            yield node
            if not self.error_limited(node):
                nodes_left -= 1
                if nodes_left &lt;= 0:
                    return
</code></pre>

<p>{% endcodeblock %}<br/>
* 1～7: 遍历每个主节点，如果节点没有错误则返回该节点，剩余节点数-1,如果剩余节点数&lt;=0,则直接返回。
* 8～22: 如果主节点中都有错误，则从剩余节点中查找满足条件的节点，查找方法和主节点查找方法雷同，只是多了一些日志的记录。</p>

<h3>exception_occurred</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def exception_occurred(self, node, typ, additional_info):
    """
    Handle logging of generic exceptions.

    :param node: dictionary of node to log the error for
    :param typ: server type
    :param additional_info: additional information to log
    """
    self.logger.exception(
        _('ERROR with %(type)s server %(ip)s:%(port)s/%(device)s re: '
          '%(info)s'),
        {'type': typ, 'ip': node['ip'], 'port': node['port'],
         'device': node['device'], 'info': additional_info})
</code></pre>

<p>{% endcodeblock %}<br/>
* 9～13: 当异常发生的时候，记录异常日志。</p>

<h3>modify_wsgi_pipeline</h3>

<p>{% codeblock lang:python %}</p>

<pre><code>def modify_wsgi_pipeline(self, pipe):
    """
    Called during WSGI pipeline creation. Modifies the WSGI pipeline
    context to ensure that mandatory middleware is present in the pipeline.

    :param pipe: A PipelineWrapper object
    """
    pipeline_was_modified = False
    for filter_spec in reversed(required_filters):
        filter_name = filter_spec['name']
        if filter_name not in pipe:
            afters = filter_spec.get('after_fn', lambda _junk: [])(pipe)
            insert_at = 0
            for after in afters:
                try:
                    insert_at = max(insert_at, pipe.index(after) + 1)
                except ValueError:  # not in pipeline; ignore it
                    pass
            self.logger.info(
                'Adding required filter %s to pipeline at position %d' %
                (filter_name, insert_at))
            ctx = pipe.create_filter(filter_name)
            pipe.insert_filter(ctx, index=insert_at)
            pipeline_was_modified = True

    if pipeline_was_modified:
        self.logger.info("Pipeline was modified. New pipeline is \"%s\".",
                         pipe)
    else:
        self.logger.debug("Pipeline is \"%s\"", pipe)
</code></pre>

<p>{% endcodeblock %}<br/>
* 8～24: 遍历定义好的中间件required_filters，如果该中间件没有在pipeline中，则将该中间件插入到pipeline，插入位置根据中间件的atfer_fn方法得到。
* 26～31: 记录人日志信息。</p>

<h3>required_filters</h3>

<p>{% codeblock lang:python %}</p>

<h1>List of entry points for mandatory middlewares.</h1>

<p>#</p>

<h1>Fields:</h1>

<p>#</p>

<h1>&ldquo;name&rdquo; (required) is the entry point name from setup.py.</h1>

<p>#</p>

<h1>&ldquo;after_fn&rdquo; (optional) a function that takes a PipelineWrapper object as its</h1>

<h1>single argument and returns a list of middlewares that this middleware</h1>

<h1>should come after. Any middlewares in the returned list that are not present</h1>

<h1>in the pipeline will be ignored, so you can safely name optional middlewares</h1>

<h1>to come after. For example, [&ldquo;catch_errors&rdquo;, &ldquo;bulk&rdquo;] would install this</h1>

<h1>middleware after catch_errors and bulk if both were present, but if bulk</h1>

<h1>were absent, would just install it after catch_errors.</h1>

<p>required_filters = [</p>

<pre><code>{'name': 'catch_errors'},
{'name': 'gatekeeper',
 'after_fn': lambda pipe: (['catch_errors']
                           if pipe.startswith("catch_errors")
                           else [])},
{'name': 'dlo', 'after_fn': lambda _junk: ['catch_errors', 'gatekeeper',
                                           'proxy_logging']}]
</code></pre>

<p>{% endcodeblock %}<br/>
* modify_wsgi_pipeline方法用到的required_filters。</p>

<h3>app_factory</h3>

<p>{% codeblock lang:python %}
def app_factory(global_conf, **local_conf):</p>

<pre><code>"""paste.deploy app factory for creating WSGI proxy apps."""
conf = global_conf.copy()
conf.update(local_conf)
app = Application(conf)
app.check_config()
return app
</code></pre>

<p>{% endcodeblock %}<br/>
* proxy server的工厂方法，初始化server对象并检查配置，然后返回创建好的对象。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[swift源码详解（一）——开始]]></title>
    <link href="http://zhaozhiming.github.io/blog/2014/04/19/swift-code-explain-total/"/>
    <updated>2014-04-19T17:19:00+08:00</updated>
    <id>http://zhaozhiming.github.io/blog/2014/04/19/swift-code-explain-total</id>
    <content type="html"><![CDATA[<p>从今天开始准备仔细再看一下swift的源码，然后把理解的内容记录下来。下面是swift源码的代码结构，准备每天更新1～2个文件的代码理解，更新好的在文件名上会在下面的代码结构上有链接出现。</p>

<!--more-->


<p>
swift的源码因为不断在更新，笔记记录的代码就以2014-4-18的为准，我已经fork了一份swift源码到我github上，地址是：<a href="https://github.com/zhaozhiming/swift">https://github.com/zhaozhiming/swift</a>，代码结构如下：</p>

<ul>
<li><h3>swift</h3>

<ul>
<li><h3>account</h3>

<ul>
<li>auditor.py</li>
<li>backend.py</li>
<li>reaper.py</li>
<li>replicator.py</li>
<li>server.py</li>
<li>utils.py</li>
</ul>
</li>
<li><h3>cli</h3>

<ul>
<li>info.py</li>
<li>recon.py</li>
<li>ringbuilder.py</li>
<li>ringbuilder.py</li>
</ul>
</li>
<li><h3>common</h3>

<ul>
<li><h3>middleware</h3>

<ul>
<li>account_quotas.py</li>
<li>acl.py</li>
<li>bulk.py</li>
<li>catch_errors.py</li>
<li>cname_lookup.py</li>
<li>container_quotas.py</li>
<li>container_sync.py</li>
<li>crossdomain.py</li>
<li>dlo.py</li>
<li>domain_remap.py</li>
<li>formpost.py</li>
<li>gatekeeper.py</li>
<li>healthcheck.py</li>
<li>list_endpoints.py</li>
<li>memcache.py</li>
<li>name_check.py</li>
<li>proxy_logging.py</li>
<li>ratelimit.py</li>
<li>recon.py</li>
<li>slo.py</li>
<li>staticweb.py</li>
<li>tempauth.py</li>
<li>tempurl.py</li>
</ul>
</li>
<li><h3>ring</h3>

<ul>
<li>builder.py</li>
<li>ring.py</li>
<li>utils.py</li>
</ul>
</li>
<li>bufferedhttp.py</li>
<li>constraints.py</li>
<li>container_sync_realms.py</li>
<li>daemon.py</li>
<li>db.py</li>
<li>db_replicator.py</li>
<li>direct_client.py</li>
<li>exceptions.py</li>
<li>http.py</li>
<li>internal_client.py</li>
<li>manager.py</li>
<li>memcached.py</li>
<li>request_helpers.py</li>
<li>swob.py</li>
<li>swob.py</li>
<li>utils.py</li>
<li>wsgi.py</li>
</ul>
</li>
<li><h3>container</h3>

<ul>
<li>auditor.py</li>
<li>backend.py</li>
<li>replicator.py</li>
<li>server.py</li>
<li>sync.py</li>
<li>updater.py</li>
</ul>
</li>
<li><h3>obj</h3>

<ul>
<li>auditor.py</li>
<li>diskfile.py</li>
<li>expirer.py</li>
<li>mem_diskfile.py</li>
<li>mem_server.py</li>
<li>replicator.py</li>
<li>server.py</li>
<li>ssync_receiver.py</li>
<li>ssync_sender.py</li>
<li>updater.py</li>
</ul>
</li>
<li><h3>proxy</h3>

<ul>
<li>controllers

<ul>
<li>account.py</li>
<li><a href="http://zhaozhiming.github.io/blog/2014/05/04/swift-code-explain-3-proxy-controllers-base/">base.py</a></li>
<li>container.py</li>
<li>obj.py</li>
</ul>
</li>
<li><a href="http://zhaozhiming.github.io/blog/2014/04/20/swift-code-explain-proxy-server/">server.py</a></li>
</ul>
</li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[swift单节点多dev环境部署]]></title>
    <link href="http://zhaozhiming.github.io/blog/2014/04/09/swift-multiply-nodes-deploy-in-one-machine/"/>
    <updated>2014-04-09T20:45:00+08:00</updated>
    <id>http://zhaozhiming.github.io/blog/2014/04/09/swift-multiply-nodes-deploy-in-one-machine</id>
    <content type="html"><![CDATA[<h2>环境目标</h2>

<ul>
<li>同一台机器</li>
<li>1台proxy server</li>
<li>5个storage node</li>
<li>每个storage node有2个dev</li>
</ul>


<!--more-->


<p></p>

<p>安装过程可以按照<a href="http://docs.openstack.org/developer/swift/development_saio.html">swift all in one</a>文档进行搭建，在操作过程中需要修改以下的地方。</p>

<h2>Using a loopback device for storage</h2>

<ol>
<li>Create the file for the loopback device:<br/>
<code>(这里的标题和编号是与saio的保持一致，这样方便大家按照saio的编号进行修改，后面的步骤与此相同，不再做说明)</code></li>
</ol>


<p>修改前：<br/>
{% codeblock lang:bash %}
sudo truncate -s 1GB /srv/swift-disk
{% endcodeblock %}</p>

<p>修改后：<br/>
{% codeblock lang:bash %}
sudo truncate -s 500GB /srv/swift-disk
{% endcodeblock %}</p>

<p>将xfs文件系统的大小改为500GB，原来的1GB太小不适合做测试。</p>

<ol>
<li>Create the mount point and the individualized links: <br/>
将原来的脚本修改为：<br/>
{% codeblock lang:bash %}
sudo mkdir /mnt/sdb1
sudo mount /mnt/sdb1
sudo mkdir /mnt/sdb1/1 /mnt/sdb1/2 /mnt/sdb1/3 /mnt/sdb1/4 /mnt/sdb1/5
sudo chown ${USER}:${USER} /mnt/sdb1/*
for x in {1..5}; do sudo ln -s /mnt/sdb1/$x /srv/$x; done
sudo mkdir -p /srv/1/node/dev1 /srv/1/node/dev2 /srv/2/node/dev3 /srv/2/node/dev4 /srv/3/node/dev5 /srv/3/node/dev6 /srv/4/node/dev7 /srv/4/node/dev8 /srv/5/node/dev9 /srv/5/node/dev10 /var/run/swift
sudo chown -R ${USER}:${USER} /var/run/swift

<h1><strong>Make sure to include the trailing slash after /srv/$x/</strong></h1>

<p>for x in {1..5}; do sudo chown -R ${USER}:${USER} /srv/$x/; done
{% endcodeblock %}</p></li>
</ol>


<p>创建属于5个节点的文件夹，在每个节点文件夹下创建2个dev文件夹，表示1个节点有2个dev，其中region1有6台dev(1~6)，region2有4台dev(7~10)。</p>

<h2>Common Post-Device Setup</h2>

<p>Add the following lines to /etc/rc.local (before the exit 0): <br/>
修改前：<br/>
{% codeblock lang:bash %}
mkdir -p /var/cache/swift /var/cache/swift2 /var/cache/swift3 /var/cache/swift4
{% endcodeblock %}</p>

<p>修改后：<br/>
{% codeblock lang:bash %}
mkdir -p /var/cache/swift /var/cache/swift2 /var/cache/swift3 /var/cache/swift4 /var/cache/swift5
{% endcodeblock %}
因为有5个节点，所以增加了1个新节点的缓存文件夹。</p>

<h2>Setting up rsync</h2>

<p>Here is the default rsyncd.conf file contents maintained in the repo that is copied and fixed up above:</p>

<p>在/etc/rsyncd.conf文件追加以下内容：</p>

<p>{% codeblock lang:bash %}
[account6052]
max connections = 25
path = /srv/5/node/
read only = false
lock file = /var/lock/account6052.lock</p>

<p>[container6051]
max connections = 25
path = /srv/5/node/
read only = false
lock file = /var/lock/container6051.lock</p>

<p>[object6050]
max connections = 25
path = /srv/5/node/
read only = false
lock file = /var/lock/object6050.lock
{% endcodeblock %}</p>

<p>增加了新节点的account, container, object服务的同步配置。</p>

<p>You should see the following output from the above command:</p>

<p>{% codeblock lang:bash %}
account6012
account6022
account6032
account6042
account6052
container6011
container6021
container6031
container6041
container6051
object6010
object6020
object6030
object6040
object6050
{% endcodeblock %}</p>

<p>验证rsync可以看到新增的account, container, object信息。</p>

<h2>Optional: Setting up rsyslog for individual logging</h2>

<p>将/etc/rsyslog.d/10-swift.conf文件内容修改为：<br/>
{% codeblock lang:bash %}</p>

<h1>Uncomment the following to have a log containing all logs together</h1>

<h1>local1,local2,local3,local4,local5.*   /var/log/swift/all.log</h1>

<h1>Uncomment the following to have hourly proxy logs for stats processing</h1>

<h1>$template HourlyProxyLog,&ldquo;/var/log/swift/hourly/%$YEAR%%$MONTH%%$DAY%%$HOUR%&rdquo;</h1>

<h1>local1.*;local1.!notice ?HourlyProxyLog</h1>

<p>local1.<em>;local1.!notice /var/log/swift/proxy.log
local1.notice           /var/log/swift/proxy.error
local1.</em>                ~</p>

<p>local2.<em>;local2.!notice /var/log/swift/storage1.log
local2.notice           /var/log/swift/storage1.error
local2.</em>                ~</p>

<p>local3.<em>;local3.!notice /var/log/swift/storage2.log
local3.notice           /var/log/swift/storage2.error
local3.</em>                ~</p>

<p>local4.<em>;local4.!notice /var/log/swift/storage3.log
local4.notice           /var/log/swift/storage3.error
local4.</em>                ~</p>

<p>local5.<em>;local5.!notice /var/log/swift/storage4.log
local5.notice           /var/log/swift/storage4.error
local5.</em>                ~</p>

<p>local6.<em>;local6.!notice /var/log/swift/storage5.log
local6.notice           /var/log/swift/storage5.error
local6.</em>                ~</p>

<p>local7.<em>;local7.!notice /var/log/swift/expirer.log
local7.notice           /var/log/swift/expirer.error
local7.</em>                ~
{% endcodeblock %}</p>

<p>修改日志配置，将原来的local6指向storage node 5, 原来的expirer用local7来记录日志（<code>注意：后面在修改各个节点的服务配置文件时需要知道这些日志配置信息</code>）。</p>

<h2>Configuring each node</h2>

<ol>
<li>/etc/swift/object-expirer.conf</li>
</ol>


<p>修改前：<br/>
{% codeblock lang:bash %}
log_facility = LOG_LOCAL6   <br/>
{% endcodeblock %}</p>

<p>修改后：<br/>
{% codeblock lang:bash %}
log_facility = LOG_LOCAL7
{% endcodeblock %}</p>

<ul>
<li>新增account5的配置文件 /etc/swift/account-server/5.conf：</li>
</ul>


<p>{% codeblock lang:bash %}
[DEFAULT]
devices = /srv/5/node
mount_check = false
disable_fallocate = true
bind_port = 6052
workers = 1
user = swift
log_facility = LOG_LOCAL6
recon_cache_path = /var/cache/swift5
eventlet_debug = true</p>

<p>[pipeline:main]
pipeline = recon account-server</p>

<p>[app:account-server]
use = egg:swift#account</p>

<p>[filter:recon]
use = egg:swift#recon</p>

<p>[account-replicator]
vm_test_mode = yes</p>

<p>[account-auditor]</p>

<p>[account-reaper]
{% endcodeblock %}</p>

<ul>
<li>新增container5的配置文件/etc/swift/container-server/5.conf：</li>
</ul>


<p>{% codeblock lang:bash %}
[DEFAULT]
devices = /srv/5/node
mount_check = false
disable_fallocate = true
bind_port = 6051
workers = 1
user = swift
log_facility = LOG_LOCAL6
recon_cache_path = /var/cache/swift5
eventlet_debug = true
allow_versions = true</p>

<p>[pipeline:main]
pipeline = recon container-server</p>

<p>[app:container-server]
use = egg:swift#container</p>

<p>[filter:recon]
use = egg:swift#recon</p>

<p>[container-replicator]
vm_test_mode = yes</p>

<p>[container-updater]</p>

<p>[container-auditor]</p>

<p>[container-sync]
{% endcodeblock %}</p>

<ul>
<li>新增object5的配置文件/etc/swift/object-server/5.conf：</li>
</ul>


<p>{% codeblock lang:bash %}
[DEFAULT]
devices = /srv/5/node
mount_check = false
disable_fallocate = true
bind_port = 6050
workers = 1
user = swift
log_facility = LOG_LOCAL6
recon_cache_path = /var/cache/swift5
eventlet_debug = true</p>

<p>[pipeline:main]
pipeline = recon object-server</p>

<p>[app:object-server]
use = egg:swift#object</p>

<p>[filter:recon]
use = egg:swift#recon</p>

<p>[object-replicator]
vm_test_mode = yes</p>

<p>[object-updater]</p>

<p>[object-auditor]
{% endcodeblock %}</p>

<h2>Setting up scripts for running Swift</h2>

<ol>
<li>Construct the initial rings using the provided script:</li>
</ol>


<p>先修改bin/remakerings文件，在执行remakerings命令：</p>

<p>{% codeblock lang:bash %}</p>

<h1>!/bin/bash</h1>

<p>cd /etc/swift</p>

<p>rm -f <em>.builder </em>.ring.gz backups/<em>.builder backups/</em>.ring.gz</p>

<p>swift-ring-builder object.builder create 19 6 1
swift-ring-builder object.builder add r1z1-127.0.0.1:6010/dev1 1
swift-ring-builder object.builder add r1z1-127.0.0.1:6010/dev2 1
swift-ring-builder object.builder add r1z2-127.0.0.1:6020/dev3 1
swift-ring-builder object.builder add r1z2-127.0.0.1:6020/dev4 1
swift-ring-builder object.builder add r1z3-127.0.0.1:6030/dev5 1
swift-ring-builder object.builder add r1z3-127.0.0.1:6030/dev6 1
swift-ring-builder object.builder add r2z1-127.0.0.1:6040/dev7 1
swift-ring-builder object.builder add r2z1-127.0.0.1:6040/dev8 1
swift-ring-builder object.builder add r2z2-127.0.0.1:6050/dev9 1
swift-ring-builder object.builder add r2z2-127.0.0.1:6050/dev10 1
swift-ring-builder object.builder rebalance
swift-ring-builder container.builder create 19 6 1
swift-ring-builder container.builder add r1z1-127.0.0.1:6011/dev1 1
swift-ring-builder container.builder add r1z1-127.0.0.1:6011/dev2 1
swift-ring-builder container.builder add r1z2-127.0.0.1:6021/dev3 1
swift-ring-builder container.builder add r1z2-127.0.0.1:6021/dev4 1
swift-ring-builder container.builder add r1z3-127.0.0.1:6031/dev5 1
swift-ring-builder container.builder add r1z3-127.0.0.1:6031/dev6 1
swift-ring-builder container.builder add r2z1-127.0.0.1:6041/dev7 1
swift-ring-builder container.builder add r2z1-127.0.0.1:6041/dev8 1
swift-ring-builder container.builder add r2z2-127.0.0.1:6051/dev9 1
swift-ring-builder container.builder add r2z2-127.0.0.1:6051/dev10 1
swift-ring-builder container.builder rebalance
swift-ring-builder account.builder create 19 6 1
swift-ring-builder account.builder add r1z1-127.0.0.1:6012/dev1 1
swift-ring-builder account.builder add r1z1-127.0.0.1:6012/dev2 1
swift-ring-builder account.builder add r1z2-127.0.0.1:6022/dev3 1
swift-ring-builder account.builder add r1z2-127.0.0.1:6022/dev4 1
swift-ring-builder account.builder add r1z3-127.0.0.1:6032/dev5 1
swift-ring-builder account.builder add r1z3-127.0.0.1:6032/dev6 1
swift-ring-builder account.builder add r2z1-127.0.0.1:6042/dev7 1
swift-ring-builder account.builder add r2z1-127.0.0.1:6042/dev8 1
swift-ring-builder account.builder add r2z2-127.0.0.1:6052/dev9 1
swift-ring-builder account.builder add r2z2-127.0.0.1:6052/dev10 1
swift-ring-builder account.builder rebalance
{% endcodeblock %}</p>

<p>新ring环有2的19次方，6个副本，修改后重新生成ring环即可。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[openstack swift中间件编写]]></title>
    <link href="http://zhaozhiming.github.io/blog/2014/02/17/how-to-write-a-openstack-swift-middle-ware/"/>
    <updated>2014-02-17T20:33:00+08:00</updated>
    <id>http://zhaozhiming.github.io/blog/2014/02/17/how-to-write-a-openstack-swift-middle-ware</id>
    <content type="html"><![CDATA[<p>{% img /images/post/2014-2/swift.jpg %}</p>

<p>关于openstack swift的资料可以看<a href="http://zh.wikipedia.org/wiki/OpenStack">这里</a>，<a href="http://www.programmer.com.cn/12403/">这里</a>还有<a href="http://www.ibm.com/developerworks/cn/cloud/library/1310_zhanghua_openstackswift/">这里</a>。</p>

<!--more-->


<p></p>

<h2>准备环境</h2>

<p>从零开始接触的同学可以先从swift的<a href="http://docs.openstack.org/developer/swift/development_saio.html">all in one</a>部署开始学习，在本机搭建好swift环境就可以进行简单的测试了。由于swift是用Python语言写的，如果要开发swift的中间件的还需要在本地安装Pythone的IDE，我比较喜欢JETBRAIN（他们比较出名的是JAVA的IDE——IDEA）公司的IDE——Pycharm。准备环境如下:</p>

<ul>
<li>Ububutn 12.04 LTS 64bit</li>
<li>Python2.7(虽然现在已经有Python3了，但swift是用2.x的Python写的，Python3不向后兼容Python2)</li>
<li>Pycharm3</li>
</ul>


<h2>中间件介绍</h2>

<p>swift通过提供基于HTTP协议的API给外界调用来完成对象存储的功能，我们从swift的各个部署说明里面可以看到，proxy server和storage node的配置文件里面都有一个<code>[pipeline:main]</code>，这个是swift各个服务的请求链，由多个中间件组成的一个中间件集合。pipeline有点像J2EE里面filter，每个http请求需要经过各个服务的pipeline。</p>

<p>{% codeblock proxy-server.conf lang:xml %}
&hellip;
[pipeline:main]</p>

<h1>Yes, proxy-logging appears twice. This is so that</h1>

<h1>middleware-originated requests get logged too.</h1>

<p>pipeline = catch_errors healthcheck proxy-logging bulk ratelimit crossdomain slo cache tempurl tempauth staticweb account-quotas container-quotas proxy-logging proxy-server
&hellip;
{% endcodeblock %}</p>

<p>{% codeblock account-server.conf lang:xml %}
&hellip;
[pipeline:main]
pipeline = recon account-server
&hellip;
{% endcodeblock %}</p>

<h2>中间件编写</h2>

<p>了解了swift的基本功能流程后，我们就可以来写自己的中间件了。</p>

<p>没有写过中间件的同学可以通过学习其他中间件开始，在swift的源码中配置了很多中间件，有一些功能非常简单。比如name_check中间件，这个中间件的作用是拿来分析请求的url，判断url中是否有特殊字符，长度是否超出规定长度等。这个中间件没有配置在swift的标准配置中，有需要的可以自行加上本机的swift环境做测试。</p>

<p>我们先来看一下name_check中间件的配置信息：</p>

<p>{% codeblock proxy-server.conf lang:xml %}
[pipeline:main]
pipeline = catch_errors healthcheck name_check cache ratelimit tempauth sos</p>

<pre><code>       proxy-logging proxy-server
</code></pre>

<p>[filter:name_check]
use = egg:swift#name_check
forbidden_chars = &lsquo;&ldquo;`&lt;>
maximum_length = 255
{% endcodeblock %}
在上面的例子中，name_check中间件加在healthcheck这个中间件后面，filter:name_check下面的配置信息是name_check的一些配置参数。</p>

<ul>
<li>forbidden_chars: 指url中不能包含的特殊字符</li>
<li>maximum_length: 指url的最大长度</li>
</ul>


<p>我们再来看name_check的单元测试：</p>

<p>{% codeblock test_name_check.py lang:python %}
class FakeApp(object):</p>

<pre><code>def __call__(self, env, start_response):
    return Response(body="OK")(env, start_response)
</code></pre>

<p>class TestNameCheckMiddleware(unittest.TestCase):</p>

<pre><code>def setUp(self):
    self.conf = {'maximum_length': MAX_LENGTH, 'forbidden_chars':
                 FORBIDDEN_CHARS, 'forbidden_regexp': FORBIDDEN_REGEXP}
    self.test_check = name_check.filter_factory(self.conf)(FakeApp())

def test_valid_length_and_character(self):
    path = '/V1.0/' + 'c' * (MAX_LENGTH - 6)
    resp = Request.blank(path, environ={'REQUEST_METHOD': 'PUT'}
                         ).get_response(self.test_check)
    self.assertEquals(resp.body, 'OK')

...... # other test cases    
</code></pre>

<p>if <strong>name</strong> == &lsquo;<strong>main</strong>&rsquo;:</p>

<pre><code>unittest.main()
</code></pre>

<p>{% endcodeblock %}
看源码先从单元测试看起，可以以最快的速度了解源代码的功能。在这个测试案例中，测试先mock了一个虚拟的app，这个app不会真实的调用swift，而是会将http response返回预设好的值。<br/>
再看其中的一个测试案例，这里给定了一个最大长度url，然后通过调用name_check中间件，期望请求可以正常通过。</p>

<p>最后我们再来看name_check中间件的<a href="https://github.com/openstack/swift/blob/master/swift/common/middleware/name_check.py">源码</a>几个方法：</p>

<ul>
<li><strong>init</strong>: 中间件的初始化方法</li>
<li><strong>call</strong>: 中间件被调用时触发的方法</li>
<li>filter_factory: 这个是类以外的方法，在swift服务启动时会创建中间件实例，并加入到pipeline中。</li>
</ul>


<p>学习完这个简单的中间件后，相信大家都可以依葫芦画瓢开始写自己的中间件了。</p>

<h2>修改配置文件</h2>

<p>编写完中间件之后，还需要将中间件配置到swift中，这样才算真正完成中间件的创建。</p>

<h4>首先先停止swift的服务</h4>

<p>{% codeblock shell lang:xml %}
swift@ubuntu:~$ swift-init main stop
{% endcodeblock %}</p>

<h4>接着修改conf文件</h4>

<p>假设你增加的中间件是proxy server的中间件，就修改proxy-server.conf，自行决定要放到pipeline中的哪个位置，具体要看你的中间件是执行什么功能。
{% codeblock proxy-server.conf lang:xml %}
[pipeline:main]
pipeline = catch_errors healthcheck your_middleware cache ratelimit tempauth sos</p>

<pre><code>       proxy-logging proxy-server
</code></pre>

<p>[filter:your_middleware]
use = egg:swift#your_middleware
your_middleware_config1 = value1
your_middleware_config1 = value2
{% endcodeblock %}</p>

<h4>要修改swift的根目录下的setup.cfg文件</h4>

<p>{% codeblock setup.cfg lang:xml %}
paste.filter_factory =</p>

<pre><code>#这里加入一行自己的中间件，可以看下name_check中间件是怎么写的
name_check = swift.common.middleware.name_check:filter_factory
</code></pre>

<p>{% endcodeblock %}</p>

<h4>执行命令重新安装swift</h4>

<p>{% codeblock shell lang:xml %}
swift@ubuntu:~$ cd swift目录
swift@ubuntu:~$ sudo python setyp.py develop
{% endcodeblock %}</p>

<h4>最后重启swift服务</h4>

<p>{% codeblock shell lang:xml %}
swift@ubuntu:~$ swift-init main start
{% endcodeblock %}</p>
]]></content>
  </entry>
  
</feed>
